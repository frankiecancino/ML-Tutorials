{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inisghts from Text using N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an introductory NLP tutorial about N-Grams and how they can be used to find information within text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Grams Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-grams are a fundamental concept in NLP that capture sequential patterns in text. They have a wide range of applications and provide valuable insights into language usage and its structure. The \"n\" in n-grams signifies the number of tokens in the sequence. Tokens are a specified number of characters. The token can be an entire word, phrase, or number of characters. A 2-gram (also called a bigram) consists of pairs of consecutive tokens, a 3-gram (trigram) consists of triplets of consecutive tokens, and so on. The choice of n depends on the task and the text being analyzed.\n",
    "\n",
    "Example of bigrams for the sentence \"the quick brown fox\":\n",
    "\n",
    "`[\"the\", \"quick\"], [\"quick\", \"brown\"], [\"brown\", \"fox\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How are N-Grams used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-grams capture local patterns in text and provide useful statistical information about the combination of words or characters in the text. By analyzing the frequencies of n-grams, models can learn patterns, predict the likelihood of certain words or phrases, and generate text that looks like the input data.\n",
    "\n",
    "One common application of n-grams is in language modeling, where the objective is to predict the next word in a sequence given the previous context.\n",
    "\n",
    "N-grams are also used in text classification tasks, such as sentiment analysis or spam detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams Example in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an example use of N-Grams using Python, to further understand how N-Grams works and their potential use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, Bigrams takes a look at the 2 consecutive tokens (or words in our case) across text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This', 'is')\n",
      "('is', 'an')\n",
      "('an', 'example')\n",
      "('example', 'bigram')\n",
      "('bigram', 'use')\n",
      "('use', 'case')\n",
      "('case', 'in')\n",
      "('in', 'Python.')\n"
     ]
    }
   ],
   "source": [
    "# Create a function to generate bigrams from text\n",
    "def generate_bigrams(text):\n",
    "    # Split the text for each word\n",
    "    words = text.split()\n",
    "    bigrams = []\n",
    "\n",
    "    # Iterate through the words\n",
    "    for i in range(len(words) - 1):\n",
    "        # Append each bigram or 2 consecutive words as a tuple\n",
    "        bigrams.append((words[i], words[i + 1]))\n",
    "\n",
    "    return bigrams\n",
    "\n",
    "# Example text\n",
    "text = \"This is an example bigram use case in Python.\"\n",
    "result = generate_bigrams(text)\n",
    "\n",
    "# Print each bigram\n",
    "for bigram in result:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now generated bigrams for any input text, in pure Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will be using NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK (Natural Language Toolkit) is a popular Python library for natural language processing (NLP). It provides various functions, classes, and tools for NLP tasks such as tokenization, stemming, parts-of-speech tagging, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('An', 'example', 'n-gram')\n",
      "('example', 'n-gram', 'use')\n",
      "('n-gram', 'use', 'case')\n",
      "('use', 'case', 'in')\n",
      "('case', 'in', 'Python.')\n",
      "('in', 'Python.', 'This')\n",
      "('Python.', 'This', 'time')\n",
      "('This', 'time', 'using')\n",
      "('time', 'using', 'nltk.')\n"
     ]
    }
   ],
   "source": [
    "# Library Imports\n",
    "from nltk import ngrams\n",
    "\n",
    "# Example usage\n",
    "text = \"An example n-gram use case in Python. This time using nltk.\"\n",
    "\n",
    "# Generate trigrams this time using the NLTK ngrams function\n",
    "ngram_result = list(ngrams(text.split(), 3))\n",
    "\n",
    "# Print each ngram\n",
    "for ngram in ngram_result:\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power of N-Grams comes from using them as a form of likelihood or context. Once the N-Grams are generated, we can identify which sequences are the most popular and identify the words before and after. This transforms your text into a richer form of information to provide downstream to models or other NLP tasks.\n",
    "\n",
    "For example, we can identify that the word \"Python\" is present 33% of the time from our example earlier. Using the information about your n-grams adds information to a broad set of NLP tasks including Language Modeling, Text Generation, Information Retrieval, Machine Translation, Text Classification, and more.\n",
    "\n",
    "Explore what information your N-Grams can give you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can you do next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Play around with NLTK! As mentioned earlier, NLTK is a powerful and popular NLP library in Python. I highly recommend exploring it more and finding out what NLP tasks can be done using the library.\n",
    "\n",
    "- Start looking at Topic Modeling, Text Classification, and other NLP topics. With Large Language Models becoming more and more popular, it helps to understand how NLP works and the evolution of the field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-grams in natural language processing (NLP) are continuous sequences of N items (typically words) that capture local linguistic patterns and are used for various downstream tasks such as language modeling, text generation, and information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frankie Cancino is a Senior Data Scientist for Mercedes-Benz Research & Development, working on machine learning use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "* [NLTK Docs](https://www.nltk.org)\n",
    "* [LinkedIn](https://www.linkedin.com/in/frankie-cancino/)\n",
    "* [Twitter](https://twitter.com/frankiecancino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
